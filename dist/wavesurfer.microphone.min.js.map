{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///wavesurfer.microphone.min.js","webpack:///webpack/bootstrap 13d1c6398860074631e7","webpack:///./src/plugin/microphone.js"],"names":["root","factory","exports","module","define","amd","self","this","modules","__webpack_require__","moduleId","installedModules","i","l","call","m","c","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","5","_classCallCheck","instance","Constructor","TypeError","value","_createClass","defineProperties","target","props","length","descriptor","writable","key","protoProps","staticProps","MicrophonePlugin","params","ws","_this","wavesurfer","active","paused","reloadBufferFunction","e","reloadBuffer","promisifiedOldGUM","constraints","successCallback","errorCallback","getUserMedia","navigator","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","Promise","reject","Error","undefined","mediaDevices","video","audio","bufferSize","numberOfInputChannels","numberOfOutputChannels","_onBackendCreated","micContext","backend","getAudioContext","deferInit","on","un","stop","_this2","then","data","gotStream","catch","deviceError","pause","play","start","connect","disconnect","stopDevice","empty","stream","result","detectBrowser","browser","version","getTracks","forEach","mediaStreamSource","createMediaStreamSource","levelChecker","createScriptProcessor","destination","onaudioprocess","event","loadDecodedBuffer","inputBuffer","fireEvent","code","uastring","expr","pos","match","parseInt","minVersion","window","extractVersion","userAgent","webkitRTCPeerConnection","default"],"mappings":";;;;;CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,IACA,kBAAAG,gBAAAC,IACAD,OAAA,gBAAAH,GACA,gBAAAC,SACAA,QAAA,WAAAD,KAEAD,EAAA,WAAAA,EAAA,eAA+CA,EAAA,sBAAAC,MAC9C,mBAAAK,WAAAC,KAAA,WACD,MCKgB,UAAUC,GCX1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAR,OAGA,IAAAC,GAAAQ,EAAAD,IACAE,EAAAF,EACAG,GAAA,EACAX,WAUA,OANAM,GAAAE,GAAAI,KAAAX,EAAAD,QAAAC,IAAAD,QAAAO,GAGAN,EAAAU,GAAA,EAGAV,EAAAD,QAvBA,GAAAS,KA4DA,OAhCAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAQ,EAAA,SAAAf,EAAAgB,EAAAC,GACAV,EAAAW,EAAAlB,EAAAgB,IACAG,OAAAC,eAAApB,EAAAgB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAV,EAAAiB,EAAA,SAAAvB,GACA,GAAAgB,GAAAhB,KAAAwB,WACA,WAA2B,MAAAxB,GAAA,SAC3B,WAAiC,MAAAA,GAEjC,OADAM,GAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAQ,EAAAC,GAAsD,MAAAR,QAAAS,UAAAC,eAAAjB,KAAAc,EAAAC,IAGtDpB,EAAAuB,EAAA,8BAGAvB,IAAAwB,EAAA,KDqBMC,EACA,SAAU/B,EAAQD,EAASO,GAEjC,YASA,SAAS0B,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCANhHjB,OAAOC,eAAepB,EAAS,cAC3BqC,OAAO,GAGX,IAAIC,GAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAI/B,GAAI,EAAGA,EAAI+B,EAAMC,OAAQhC,IAAK,CAAE,GAAIiC,GAAaF,EAAM/B,EAAIiC,GAAWrB,WAAaqB,EAAWrB,aAAc,EAAOqB,EAAWtB,cAAe,EAAU,SAAWsB,KAAYA,EAAWC,UAAW,GAAMzB,OAAOC,eAAeoB,EAAQG,EAAWE,IAAKF,IAAiB,MAAO,UAAUR,EAAaW,EAAYC,GAAiJ,MAA9HD,IAAYP,EAAiBJ,EAAYP,UAAWkB,GAAiBC,GAAaR,EAAiBJ,EAAaY,GAAqBZ,MErD3gBa,EFgGE,WE7EnB,QAAAA,GAAYC,EAAQC,GAAI,GAAAC,GAAA9C,IAAA4B,GAAA5B,KAAA2C,GACpB3C,KAAK4C,OAASA,EACd5C,KAAK+C,WAAaF,EAElB7C,KAAKgD,QAAS,EACdhD,KAAKiD,QAAS,EACdjD,KAAKkD,qBAAuB,SAAAC,GAAA,MAAKL,GAAKM,aAAaD,GAGnD,IAAME,GAAoB,SACtBC,EACAC,EACAC,GAGA,GAAMC,GACFC,UAAUD,cACVC,UAAUC,oBACVD,UAAUE,iBACVF,UAAUG,cAGd,OAAKJ,GAOE,GAAIK,SAAQ,SAACP,EAAiBC,GACjCC,EAAalD,KACTmD,UACAJ,EACAC,EACAC,KAXGM,QAAQC,OACX,GAAIC,OAAM,yDAgBSC,KAA3BP,UAAUQ,eACVR,UAAUQ,qBAM8BD,KAAxCP,UAAUQ,aAAaT,eACvBC,UAAUQ,aAAaT,aAAeJ,GAE1CrD,KAAKsD,YAActD,KAAK4C,OAAOU,cAC3Ba,OAAO,EACPC,OAAO,GAEXpE,KAAKqE,WAAarE,KAAK4C,OAAOyB,YAAc,KAC5CrE,KAAKsE,sBAAwBtE,KAAK4C,OAAO0B,uBAAyB,EAClEtE,KAAKuE,uBAAyBvE,KAAK4C,OAAO2B,wBAA0B,EAEpEvE,KAAKwE,kBAAoB,WAErB1B,EAAK2B,WAAa3B,EAAKC,WAAW2B,QAAQC,mBF0XlD,MAxWA1C,GAAaU,EAAkB,OAC3BH,IAAK,SAWLR,MAAO,SEnGGY,GACV,OACIjC,KAAM,aACNiE,aAAWhC,IAAUA,EAAOgC,YAAYhC,EAAOgC,UAC/ChC,OAAQA,EACRf,SAAUc,OF+JlBV,EAAaU,IACTH,IAAK,OACLR,MAAO,WE5FPhC,KAAK+C,WAAW8B,GAAG,kBAAmB7E,KAAKwE,mBACvCxE,KAAK+C,WAAW2B,SAChB1E,KAAKwE,uBFsGThC,IAAK,UACLR,MAAO,WE7FPhC,KAAKiD,QAAS,EAEdjD,KAAK+C,WAAW+B,GAAG,kBAAmB9E,KAAKwE,mBAC3CxE,KAAK+E,UFyGLvC,IAAK,QACLR,MAAO,WEnGH,GAAAgD,GAAAhF,IACJ0D,WAAUQ,aACLT,aAAazD,KAAKsD,aAClB2B,KAAK,SAAAC,GAAA,MAAQF,GAAKG,UAAUD,KAC5BE,MAAM,SAAAF,GAAA,MAAQF,GAAKK,YAAYH,QF8GpC1C,IAAK,aACLR,MAAO,WExGFhC,KAAKgD,QAKNhD,KAAKiD,QAAUjD,KAAKiD,OAEhBjD,KAAKiD,OACLjD,KAAKsF,QAELtF,KAAKuF,QARTvF,KAAKwF,WF2HThD,IAAK,OACLR,MAAO,WE3GPhC,KAAKiD,QAAS,EAEdjD,KAAKyF,aFoHLjD,IAAK,QACLR,MAAO,WE9GPhC,KAAKiD,QAAS,EAIdjD,KAAK0F,gBFwHLlD,IAAK,OACLR,MAAO,WEjHHhC,KAAKgD,SAELhD,KAAK2F,aAGL3F,KAAK+C,WAAW6C,YF2HpBpD,IAAK,aACLR,MAAO,WE9GP,GANAhC,KAAKgD,QAAS,EAGdhD,KAAK0F,aAGD1F,KAAK6F,OAAQ,CACb,GAAMC,GAAS9F,KAAK+F,eAIpB,KACwB,WAAnBD,EAAOE,SAAwBF,EAAOG,SAAW,IAC9B,YAAnBH,EAAOE,SAAyBF,EAAOG,SAAW,IAChC,SAAnBH,EAAOE,UAEHhG,KAAK6F,OAAOK,UAGZ,WADAlG,MAAK6F,OAAOK,YAAYC,QAAQ,SAAAN,GAAA,MAAUA,GAAOd,QAKzD/E,MAAK6F,OAAOd,WF4HhBvC,IAAK,UACLR,MAAO,eErHaiC,KAAhBjE,KAAK6F,SAEL7F,KAAKoG,kBAAoBpG,KAAKyE,WAAW4B,wBACrCrG,KAAK6F,QAGT7F,KAAKsG,aAAetG,KAAKyE,WAAW8B,sBAChCvG,KAAKqE,WACLrE,KAAKsE,sBACLtE,KAAKuE,wBAETvE,KAAKoG,kBAAkBX,QAAQzF,KAAKsG,cAEpCtG,KAAKsG,aAAab,QAAQzF,KAAKyE,WAAW+B,aAC1CxG,KAAKsG,aAAaG,eAAiBzG,KAAKkD,yBFyH5CV,IAAK,aACLR,MAAO,eElHwBiC,KAA3BjE,KAAKoG,mBACLpG,KAAKoG,kBAAkBV,iBAGDzB,KAAtBjE,KAAKsG,eACLtG,KAAKsG,aAAaZ,aAClB1F,KAAKsG,aAAaG,mBAAiBxC,OF4HvCzB,IAAK,eACLR,MAAO,SEtHE0E,GACJ1G,KAAKiD,SACNjD,KAAK+C,WAAW6C,QAChB5F,KAAK+C,WAAW4D,kBAAkBD,EAAME,iBFiI5CpE,IAAK,YACLR,MAAO,SEzHD6D,GACN7F,KAAK6F,OAASA,EACd7F,KAAKgD,QAAS,EAGdhD,KAAKuF,OAGLvF,KAAK6G,UAAU,cAAehB,MFiI9BrD,IAAK,cACLR,MAAO,SE5HC8E,GAER9G,KAAK6G,UAAU,cAAeC,MFwI9BtE,IAAK,iBACLR,MAAO,SE/HI+E,EAAUC,EAAMC,GAC3B,GAAMC,GAAQH,EAASG,MAAMF,EAC7B,OAAOE,IAASA,EAAM7E,QAAU4E,GAAOE,SAASD,EAAMD,GAAM,OFyI5DzE,IAAK,gBACLR,MAAO,WEhIP,GAAM8D,KAMN,OALAA,GAAOE,QAAU,KACjBF,EAAOG,QAAU,KACjBH,EAAOsB,WAAa,KAGE,mBAAXC,SAA2BA,OAAO3D,UAMzCA,UAAUE,iBACVkC,EAAOE,QAAU,UACjBF,EAAOG,QAAUjG,KAAKsH,eAClB5D,UAAU6D,UACV,sBACA,GAEJzB,EAAOsB,WAAa,GACbtB,GAIPpC,UAAUC,oBAAsB0D,OAAOG,yBACvC1B,EAAOE,QAAU,SACjBF,EAAOG,QAAUjG,KAAKsH,eAClB5D,UAAU6D,UACV,2BACA,GAEJzB,EAAOsB,WAAa,GACbtB,GAKPpC,UAAUQ,cACVR,UAAU6D,UAAUL,MAAM,uBAE1BpB,EAAOE,QAAU,OACjBF,EAAOG,QAAUjG,KAAKsH,eAClB5D,UAAU6D,UACV,qBACA,GAEJzB,EAAOsB,WAAa,MACbtB,IAIXA,EAAOE,QAAU,2BACVF,IA7CHA,EAAOE,QAAU,2BACVF,OFmKRnD,IAGXhD,GAAQ8H,QE5ca9E,EF6crB/C,EAAOD,QAAUA,EAAiB","file":"wavesurfer.microphone.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"microphone\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"microphone\"] = factory();\n\telse\n\t\troot[\"WaveSurfer\"] = root[\"WaveSurfer\"] || {}, root[\"WaveSurfer\"][\"microphone\"] = factory();\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","/*!\n * wavesurfer.js 2.0.5 (Sun Mar 04 2018 20:10:16 GMT+0100 (CET))\n * https://github.com/katspaugh/wavesurfer.js\n * @license BSD-3-Clause\n */\n(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"microphone\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"microphone\"] = factory();\n\telse\n\t\troot[\"WaveSurfer\"] = root[\"WaveSurfer\"] || {}, root[\"WaveSurfer\"][\"microphone\"] = factory();\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"localhost:8080/dist/plugin/\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 5);\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ 5:\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * @typedef {Object} MicrophonePluginParams\n * @property {MediaStreamConstraints} constraints The constraints parameter is a\n * MediaStreamConstaints object with two members: video and audio, describing\n * the media types requested. Either or both must be specified.\n * @property {number} bufferSize=4096 The buffer size in units of sample-frames.\n * If specified, the bufferSize must be one of the following values: `256`,\n * `512`, `1024`, `2048`, `4096`, `8192`, `16384`\n * @property {number} numberOfInputChannels=1 Integer specifying the number of\n * channels for this node's input. Values of up to 32 are supported.\n * @property {?boolean} deferInit Set to true to manually call\n * `initPlugin('microphone')`\n */\n\n/**\n * Visualise microphone input in a wavesurfer instance.\n *\n * @implements {PluginClass}\n * @extends {Observer}\n * @example\n * // es6\n * import MicrophonePlugin from 'wavesurfer.microphone.js';\n *\n * // commonjs\n * var MicrophonePlugin = require('wavesurfer.microphone.js');\n *\n * // if you are using <script> tags\n * var MicrophonePlugin = window.WaveSurfer.microphone;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     MicrophonePlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nvar MicrophonePlugin = function () {\n    _createClass(MicrophonePlugin, null, [{\n        key: 'create',\n\n        /**\n         * Microphone plugin definition factory\n         *\n         * This function must be used to create a plugin definition which can be\n         * used by wavesurfer to correctly instantiate the plugin.\n         *\n         * @param  {MicrophonePluginParams} params parameters use to initialise the plugin\n         * @return {PluginDefinition} an object representing the plugin\n         */\n        value: function create(params) {\n            return {\n                name: 'microphone',\n                deferInit: params && params.deferInit ? params.deferInit : false,\n                params: params,\n                instance: MicrophonePlugin\n            };\n        }\n    }]);\n\n    function MicrophonePlugin(params, ws) {\n        var _this = this;\n\n        _classCallCheck(this, MicrophonePlugin);\n\n        this.params = params;\n        this.wavesurfer = ws;\n\n        this.active = false;\n        this.paused = false;\n        this.reloadBufferFunction = function (e) {\n            return _this.reloadBuffer(e);\n        };\n\n        // cross-browser getUserMedia\n        var promisifiedOldGUM = function promisifiedOldGUM(constraints, successCallback, errorCallback) {\n            // get ahold of getUserMedia, if present\n            var getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n            // Some browsers just don't implement it - return a rejected\n            // promise with an error to keep a consistent interface\n            if (!getUserMedia) {\n                return Promise.reject(new Error('getUserMedia is not implemented in this browser'));\n            }\n            // otherwise, wrap the call to the old navigator.getUserMedia with\n            // a Promise\n            return new Promise(function (successCallback, errorCallback) {\n                getUserMedia.call(navigator, constraints, successCallback, errorCallback);\n            });\n        };\n        // Older browsers might not implement mediaDevices at all, so we set an\n        // empty object first\n        if (navigator.mediaDevices === undefined) {\n            navigator.mediaDevices = {};\n        }\n        // Some browsers partially implement mediaDevices. We can't just assign\n        // an object with getUserMedia as it would overwrite existing\n        // properties. Here, we will just add the getUserMedia property if it's\n        // missing.\n        if (navigator.mediaDevices.getUserMedia === undefined) {\n            navigator.mediaDevices.getUserMedia = promisifiedOldGUM;\n        }\n        this.constraints = this.params.constraints || {\n            video: false,\n            audio: true\n        };\n        this.bufferSize = this.params.bufferSize || 4096;\n        this.numberOfInputChannels = this.params.numberOfInputChannels || 1;\n        this.numberOfOutputChannels = this.params.numberOfOutputChannels || 1;\n\n        this._onBackendCreated = function () {\n            // wavesurfer's AudioContext where we'll route the mic signal to\n            _this.micContext = _this.wavesurfer.backend.getAudioContext();\n        };\n    }\n\n    _createClass(MicrophonePlugin, [{\n        key: 'init',\n        value: function init() {\n            this.wavesurfer.on('backend-created', this._onBackendCreated);\n            if (this.wavesurfer.backend) {\n                this._onBackendCreated();\n            }\n        }\n\n        /**\n         * Destroy the microphone plugin.\n         */\n\n    }, {\n        key: 'destroy',\n        value: function destroy() {\n            // make sure the buffer is not redrawn during\n            // cleanup and demolition of this plugin.\n            this.paused = true;\n\n            this.wavesurfer.un('backend-created', this._onBackendCreated);\n            this.stop();\n        }\n\n        /**\n         * Allow user to select audio input device, eg. microphone, and\n         * start the visualization.\n         */\n\n    }, {\n        key: 'start',\n        value: function start() {\n            var _this2 = this;\n\n            navigator.mediaDevices.getUserMedia(this.constraints).then(function (data) {\n                return _this2.gotStream(data);\n            }).catch(function (data) {\n                return _this2.deviceError(data);\n            });\n        }\n\n        /**\n         * Pause/resume visualization.\n         */\n\n    }, {\n        key: 'togglePlay',\n        value: function togglePlay() {\n            if (!this.active) {\n                // start it first\n                this.start();\n            } else {\n                // toggle paused\n                this.paused = !this.paused;\n\n                if (this.paused) {\n                    this.pause();\n                } else {\n                    this.play();\n                }\n            }\n        }\n\n        /**\n         * Play visualization.\n         */\n\n    }, {\n        key: 'play',\n        value: function play() {\n            this.paused = false;\n\n            this.connect();\n        }\n\n        /**\n         * Pause visualization.\n         */\n\n    }, {\n        key: 'pause',\n        value: function pause() {\n            this.paused = true;\n\n            // disconnect sources so they can be used elsewhere\n            // (eg. during audio playback)\n            this.disconnect();\n        }\n\n        /**\n         * Stop the device stream and remove any remaining waveform drawing from\n         * the wavesurfer canvas.\n         */\n\n    }, {\n        key: 'stop',\n        value: function stop() {\n            if (this.active) {\n                // stop visualization and device\n                this.stopDevice();\n\n                // empty last frame\n                this.wavesurfer.empty();\n            }\n        }\n\n        /**\n         * Stop the device and the visualization.\n         */\n\n    }, {\n        key: 'stopDevice',\n        value: function stopDevice() {\n            this.active = false;\n\n            // stop visualization\n            this.disconnect();\n\n            // stop stream from device\n            if (this.stream) {\n                var result = this.detectBrowser();\n                // MediaStream.stop is deprecated since:\n                // - Firefox 44 (https://www.fxsitecompat.com/en-US/docs/2015/mediastream-stop-has-been-deprecated/)\n                // - Chrome 45 (https://developers.google.com/web/updates/2015/07/mediastream-deprecations)\n                if (result.browser === 'chrome' && result.version >= 45 || result.browser === 'firefox' && result.version >= 44 || result.browser === 'edge') {\n                    if (this.stream.getTracks) {\n                        // note that this should not be a call\n                        this.stream.getTracks().forEach(function (stream) {\n                            return stream.stop();\n                        });\n                        return;\n                    }\n                }\n\n                this.stream.stop();\n            }\n        }\n\n        /**\n         * Connect the media sources that feed the visualization.\n         */\n\n    }, {\n        key: 'connect',\n        value: function connect() {\n            if (this.stream !== undefined) {\n                // Create an AudioNode from the stream.\n                this.mediaStreamSource = this.micContext.createMediaStreamSource(this.stream);\n\n                this.levelChecker = this.micContext.createScriptProcessor(this.bufferSize, this.numberOfInputChannels, this.numberOfOutputChannels);\n                this.mediaStreamSource.connect(this.levelChecker);\n\n                this.levelChecker.connect(this.micContext.destination);\n                this.levelChecker.onaudioprocess = this.reloadBufferFunction;\n            }\n        }\n\n        /**\n         * Disconnect the media sources that feed the visualization.\n         */\n\n    }, {\n        key: 'disconnect',\n        value: function disconnect() {\n            if (this.mediaStreamSource !== undefined) {\n                this.mediaStreamSource.disconnect();\n            }\n\n            if (this.levelChecker !== undefined) {\n                this.levelChecker.disconnect();\n                this.levelChecker.onaudioprocess = undefined;\n            }\n        }\n\n        /**\n         * Redraw the waveform.\n         */\n\n    }, {\n        key: 'reloadBuffer',\n        value: function reloadBuffer(event) {\n            if (!this.paused) {\n                this.wavesurfer.empty();\n                this.wavesurfer.loadDecodedBuffer(event.inputBuffer);\n            }\n        }\n\n        /**\n         * Audio input device is ready.\n         *\n         * @param {LocalMediaStream} stream The microphone's media stream.\n         */\n\n    }, {\n        key: 'gotStream',\n        value: function gotStream(stream) {\n            this.stream = stream;\n            this.active = true;\n\n            // start visualization\n            this.play();\n\n            // notify listeners\n            this.fireEvent('deviceReady', stream);\n        }\n\n        /**\n         * Device error callback.\n         */\n\n    }, {\n        key: 'deviceError',\n        value: function deviceError(code) {\n            // notify listeners\n            this.fireEvent('deviceError', code);\n        }\n\n        /**\n         * Extract browser version out of the provided user agent string.\n         * @param {!string} uastring userAgent string.\n         * @param {!string} expr Regular expression used as match criteria.\n         * @param {!number} pos position in the version string to be returned.\n         * @return {!number} browser version.\n         */\n\n    }, {\n        key: 'extractVersion',\n        value: function extractVersion(uastring, expr, pos) {\n            var match = uastring.match(expr);\n            return match && match.length >= pos && parseInt(match[pos], 10);\n        }\n\n        /**\n         * Browser detector.\n         * @return {object} result containing browser, version and minVersion\n         *     properties.\n         */\n\n    }, {\n        key: 'detectBrowser',\n        value: function detectBrowser() {\n            // Returned result object.\n            var result = {};\n            result.browser = null;\n            result.version = null;\n            result.minVersion = null;\n\n            // Non supported browser.\n            if (typeof window === 'undefined' || !window.navigator) {\n                result.browser = 'Not a supported browser.';\n                return result;\n            }\n\n            // Firefox.\n            if (navigator.mozGetUserMedia) {\n                result.browser = 'firefox';\n                result.version = this.extractVersion(navigator.userAgent, /Firefox\\/([0-9]+)\\./, 1);\n                result.minVersion = 31;\n                return result;\n            }\n\n            // Chrome/Chromium/Webview.\n            if (navigator.webkitGetUserMedia && window.webkitRTCPeerConnection) {\n                result.browser = 'chrome';\n                result.version = this.extractVersion(navigator.userAgent, /Chrom(e|ium)\\/([0-9]+)\\./, 2);\n                result.minVersion = 38;\n                return result;\n            }\n\n            // Edge.\n            if (navigator.mediaDevices && navigator.userAgent.match(/Edge\\/(\\d+).(\\d+)$/)) {\n                result.browser = 'edge';\n                result.version = this.extractVersion(navigator.userAgent, /Edge\\/(\\d+).(\\d+)$/, 2);\n                result.minVersion = 10547;\n                return result;\n            }\n\n            // Non supported browser default.\n            result.browser = 'Not a supported browser.';\n            return result;\n        }\n    }]);\n\n    return MicrophonePlugin;\n}();\n\nexports.default = MicrophonePlugin;\nmodule.exports = exports['default'];\n\n/***/ })\n\n/******/ });\n});\n\n\n// WEBPACK FOOTER //\n// wavesurfer.microphone.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"localhost:8080/dist/plugin/\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 5);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 13d1c6398860074631e7","/**\n * @typedef {Object} MicrophonePluginParams\n * @property {MediaStreamConstraints} constraints The constraints parameter is a\n * MediaStreamConstaints object with two members: video and audio, describing\n * the media types requested. Either or both must be specified.\n * @property {number} bufferSize=4096 The buffer size in units of sample-frames.\n * If specified, the bufferSize must be one of the following values: `256`,\n * `512`, `1024`, `2048`, `4096`, `8192`, `16384`\n * @property {number} numberOfInputChannels=1 Integer specifying the number of\n * channels for this node's input. Values of up to 32 are supported.\n * @property {?boolean} deferInit Set to true to manually call\n * `initPlugin('microphone')`\n */\n\n/**\n * Visualise microphone input in a wavesurfer instance.\n *\n * @implements {PluginClass}\n * @extends {Observer}\n * @example\n * // es6\n * import MicrophonePlugin from 'wavesurfer.microphone.js';\n *\n * // commonjs\n * var MicrophonePlugin = require('wavesurfer.microphone.js');\n *\n * // if you are using <script> tags\n * var MicrophonePlugin = window.WaveSurfer.microphone;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     MicrophonePlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nexport default class MicrophonePlugin {\n    /**\n     * Microphone plugin definition factory\n     *\n     * This function must be used to create a plugin definition which can be\n     * used by wavesurfer to correctly instantiate the plugin.\n     *\n     * @param  {MicrophonePluginParams} params parameters use to initialise the plugin\n     * @return {PluginDefinition} an object representing the plugin\n     */\n    static create(params) {\n        return {\n            name: 'microphone',\n            deferInit: params && params.deferInit ? params.deferInit : false,\n            params: params,\n            instance: MicrophonePlugin\n        };\n    }\n\n    constructor(params, ws) {\n        this.params = params;\n        this.wavesurfer = ws;\n\n        this.active = false;\n        this.paused = false;\n        this.reloadBufferFunction = e => this.reloadBuffer(e);\n\n        // cross-browser getUserMedia\n        const promisifiedOldGUM = (\n            constraints,\n            successCallback,\n            errorCallback\n        ) => {\n            // get ahold of getUserMedia, if present\n            const getUserMedia =\n                navigator.getUserMedia ||\n                navigator.webkitGetUserMedia ||\n                navigator.mozGetUserMedia ||\n                navigator.msGetUserMedia;\n            // Some browsers just don't implement it - return a rejected\n            // promise with an error to keep a consistent interface\n            if (!getUserMedia) {\n                return Promise.reject(\n                    new Error('getUserMedia is not implemented in this browser')\n                );\n            }\n            // otherwise, wrap the call to the old navigator.getUserMedia with\n            // a Promise\n            return new Promise((successCallback, errorCallback) => {\n                getUserMedia.call(\n                    navigator,\n                    constraints,\n                    successCallback,\n                    errorCallback\n                );\n            });\n        };\n        // Older browsers might not implement mediaDevices at all, so we set an\n        // empty object first\n        if (navigator.mediaDevices === undefined) {\n            navigator.mediaDevices = {};\n        }\n        // Some browsers partially implement mediaDevices. We can't just assign\n        // an object with getUserMedia as it would overwrite existing\n        // properties. Here, we will just add the getUserMedia property if it's\n        // missing.\n        if (navigator.mediaDevices.getUserMedia === undefined) {\n            navigator.mediaDevices.getUserMedia = promisifiedOldGUM;\n        }\n        this.constraints = this.params.constraints || {\n            video: false,\n            audio: true\n        };\n        this.bufferSize = this.params.bufferSize || 4096;\n        this.numberOfInputChannels = this.params.numberOfInputChannels || 1;\n        this.numberOfOutputChannels = this.params.numberOfOutputChannels || 1;\n\n        this._onBackendCreated = () => {\n            // wavesurfer's AudioContext where we'll route the mic signal to\n            this.micContext = this.wavesurfer.backend.getAudioContext();\n        };\n    }\n\n    init() {\n        this.wavesurfer.on('backend-created', this._onBackendCreated);\n        if (this.wavesurfer.backend) {\n            this._onBackendCreated();\n        }\n    }\n\n    /**\n     * Destroy the microphone plugin.\n     */\n    destroy() {\n        // make sure the buffer is not redrawn during\n        // cleanup and demolition of this plugin.\n        this.paused = true;\n\n        this.wavesurfer.un('backend-created', this._onBackendCreated);\n        this.stop();\n    }\n\n    /**\n     * Allow user to select audio input device, eg. microphone, and\n     * start the visualization.\n     */\n    start() {\n        navigator.mediaDevices\n            .getUserMedia(this.constraints)\n            .then(data => this.gotStream(data))\n            .catch(data => this.deviceError(data));\n    }\n\n    /**\n     * Pause/resume visualization.\n     */\n    togglePlay() {\n        if (!this.active) {\n            // start it first\n            this.start();\n        } else {\n            // toggle paused\n            this.paused = !this.paused;\n\n            if (this.paused) {\n                this.pause();\n            } else {\n                this.play();\n            }\n        }\n    }\n\n    /**\n     * Play visualization.\n     */\n    play() {\n        this.paused = false;\n\n        this.connect();\n    }\n\n    /**\n     * Pause visualization.\n     */\n    pause() {\n        this.paused = true;\n\n        // disconnect sources so they can be used elsewhere\n        // (eg. during audio playback)\n        this.disconnect();\n    }\n\n    /**\n     * Stop the device stream and remove any remaining waveform drawing from\n     * the wavesurfer canvas.\n     */\n    stop() {\n        if (this.active) {\n            // stop visualization and device\n            this.stopDevice();\n\n            // empty last frame\n            this.wavesurfer.empty();\n        }\n    }\n\n    /**\n     * Stop the device and the visualization.\n     */\n    stopDevice() {\n        this.active = false;\n\n        // stop visualization\n        this.disconnect();\n\n        // stop stream from device\n        if (this.stream) {\n            const result = this.detectBrowser();\n            // MediaStream.stop is deprecated since:\n            // - Firefox 44 (https://www.fxsitecompat.com/en-US/docs/2015/mediastream-stop-has-been-deprecated/)\n            // - Chrome 45 (https://developers.google.com/web/updates/2015/07/mediastream-deprecations)\n            if (\n                (result.browser === 'chrome' && result.version >= 45) ||\n                (result.browser === 'firefox' && result.version >= 44) ||\n                result.browser === 'edge'\n            ) {\n                if (this.stream.getTracks) {\n                    // note that this should not be a call\n                    this.stream.getTracks().forEach(stream => stream.stop());\n                    return;\n                }\n            }\n\n            this.stream.stop();\n        }\n    }\n\n    /**\n     * Connect the media sources that feed the visualization.\n     */\n    connect() {\n        if (this.stream !== undefined) {\n            // Create an AudioNode from the stream.\n            this.mediaStreamSource = this.micContext.createMediaStreamSource(\n                this.stream\n            );\n\n            this.levelChecker = this.micContext.createScriptProcessor(\n                this.bufferSize,\n                this.numberOfInputChannels,\n                this.numberOfOutputChannels\n            );\n            this.mediaStreamSource.connect(this.levelChecker);\n\n            this.levelChecker.connect(this.micContext.destination);\n            this.levelChecker.onaudioprocess = this.reloadBufferFunction;\n        }\n    }\n\n    /**\n     * Disconnect the media sources that feed the visualization.\n     */\n    disconnect() {\n        if (this.mediaStreamSource !== undefined) {\n            this.mediaStreamSource.disconnect();\n        }\n\n        if (this.levelChecker !== undefined) {\n            this.levelChecker.disconnect();\n            this.levelChecker.onaudioprocess = undefined;\n        }\n    }\n\n    /**\n     * Redraw the waveform.\n     */\n    reloadBuffer(event) {\n        if (!this.paused) {\n            this.wavesurfer.empty();\n            this.wavesurfer.loadDecodedBuffer(event.inputBuffer);\n        }\n    }\n\n    /**\n     * Audio input device is ready.\n     *\n     * @param {LocalMediaStream} stream The microphone's media stream.\n     */\n    gotStream(stream) {\n        this.stream = stream;\n        this.active = true;\n\n        // start visualization\n        this.play();\n\n        // notify listeners\n        this.fireEvent('deviceReady', stream);\n    }\n\n    /**\n     * Device error callback.\n     */\n    deviceError(code) {\n        // notify listeners\n        this.fireEvent('deviceError', code);\n    }\n\n    /**\n     * Extract browser version out of the provided user agent string.\n     * @param {!string} uastring userAgent string.\n     * @param {!string} expr Regular expression used as match criteria.\n     * @param {!number} pos position in the version string to be returned.\n     * @return {!number} browser version.\n     */\n    extractVersion(uastring, expr, pos) {\n        const match = uastring.match(expr);\n        return match && match.length >= pos && parseInt(match[pos], 10);\n    }\n\n    /**\n     * Browser detector.\n     * @return {object} result containing browser, version and minVersion\n     *     properties.\n     */\n    detectBrowser() {\n        // Returned result object.\n        const result = {};\n        result.browser = null;\n        result.version = null;\n        result.minVersion = null;\n\n        // Non supported browser.\n        if (typeof window === 'undefined' || !window.navigator) {\n            result.browser = 'Not a supported browser.';\n            return result;\n        }\n\n        // Firefox.\n        if (navigator.mozGetUserMedia) {\n            result.browser = 'firefox';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Firefox\\/([0-9]+)\\./,\n                1\n            );\n            result.minVersion = 31;\n            return result;\n        }\n\n        // Chrome/Chromium/Webview.\n        if (navigator.webkitGetUserMedia && window.webkitRTCPeerConnection) {\n            result.browser = 'chrome';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Chrom(e|ium)\\/([0-9]+)\\./,\n                2\n            );\n            result.minVersion = 38;\n            return result;\n        }\n\n        // Edge.\n        if (\n            navigator.mediaDevices &&\n            navigator.userAgent.match(/Edge\\/(\\d+).(\\d+)$/)\n        ) {\n            result.browser = 'edge';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Edge\\/(\\d+).(\\d+)$/,\n                2\n            );\n            result.minVersion = 10547;\n            return result;\n        }\n\n        // Non supported browser default.\n        result.browser = 'Not a supported browser.';\n        return result;\n    }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/plugin/microphone.js"],"sourceRoot":""}